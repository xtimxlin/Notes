export const notes = [
    { header: 'Questions',
        detail: 'Overall interview Process and the timeline to onboard this position\n' +
            'Can you tell me about the team structure?\n' +

            'what are the most critical skills you are looking for in an ideal candidate? \n' +
            'what are the top priorities for the QA team in the next 3 to 6 months?\n'+
            'What is the team’s expectation on this role? (first 30 60 and 90 days)\n' +

            'What challenge that this role might face \n' +
            'How do you currently handle the balance between manual and automated testing? Are there specific areas where you expect more automation?\n'+
            'Can you tell me more about how the QA team collaborates with the engineering and data science teams?\n'+
            'What are some of the biggest challenges the QA team is currently facing?\n'+
            'What do you enjoy most about working at EvolutionIQ, and what do you see as the biggest opportunity for the company in the next year?\n'+
            '\n'+
            ''+
            ''+

            'when can I expect to hear back? \n' +

            'I really appreciate the opportunity to interview. I’m not sure if we’ll connect again, but before we wrap up, could you share any feedback on how I could better prepare for interviews in the future?\n' +
            'Do you have any concerns about my qualifications for this job?\n' },
    { header: 'Self Intro',
        detail: 'In my most recent role at Planet Howl, it is a commission platform, makes conection between social media like FB, IG and use the creator’s connection to help merchant to sell their product, and for every transition creator will get commission ,i worded  as SDET\n' +
            'I collaborated with cross-functional teams to maintain quality for their creator and brand marketplace platform. \n' +
            'I monitored data trends for over 100 merchants to ensuring the functionality and uncovering potential issues on their production env.\n' +
            ' I also validated merchant tracking tags and performed across platforms and browser testing in Mac, Windows, Android, and IOS with chrome, firefox, safari browsers.\n' +
            '\n' +
            'Previously at (MyVest),it is a fintech company, they focus on building and maintain the investment system, i worked as automation engineer\n' +
            'I developed and maintained automated testing solutions for their financial investment platform to ensure functionalities in client account management and financial data workflows through automation. \n' +
            'I also design test cases based on PRD and break them into unit, integration, and e2e levels.\n' +
            '\n' +
            'At TCS, supporting Nationwide, \n' +
            'I develop and maintain automation tests for their automobile insurance system. \n' +
            'I focused on testing the policy creation and policy change workflow.\n' +
            'work with the manual tester to generate test data and validate the result thought automation in UI and API thought external system.\n' +
            '\n' +
            'the most comfortable technologies I use are\n' +
            'Python, \n' +
            'playwright for UI testing, \n' +
            'request for API test, \n' +
            'Postman for manual API testing and test data generation, \n' +
            'Jenkins for CI/CD, \n' +
            'MySQL for databases, \n' +
            'Jira for issue tracking, \n' +
            'Charles Proxy for mobile testing, and \n' +
            'GitHub for source control.\n' },
    { header: 'about EvolutionIQ', detail: 'EvolutionIQ is a company using machine learning to improve the insurance industry. It focused on helping injured and disabled workers get back to work faster by making claims processes more efficient. The platform uses machine learning technology to solve real-world complex problems.\n' +
            '\n'+
            'EvolutionIQ is a company focused on helping injured workers get back to work faster by using AI technology to reducing claim processing times and also use AI to solve complex problem in insurance industry\n' },
    { header: 'Why EvolutionIQ', detail: 'I am excited about EvolutionIQ because of its mission to help injured and disabled workers return to work. It feels good to be part of a company that makes a real impact on people\'s lives and also improves the insurance process by using AI . I also like that EvolutionIQ is growing fast, uses new technologies. It’s a great place to grow and contribute.' },
    { header: 'Why This Role', detail: 'This role excites me because I love QA automation and tools like Jenkins CICD, Playwright, and Pytest. I’m passionate about ensuring software works well in both frontend and backend. It’s a great opportunity to use my skills and learn more.' },
    { header: 'next role', detail: 'In my next role, I want to work on interesting projects where I can learn new skills, work with a great team to create high-quality products. And a culture that encourages me to continue to learn and improve my skill set, and the opportunity to take responsibility on new area.' },
    { header: 'stay update new tech', detail: 'I stay updated on QA trends and technologies by combining team collaboration and personal learning.\n' +
            'At Planet Howl, they had bi-weekly knowledge-sharing sessions where team members discussed new tools and techniques. This helped the entire team to learn and practices new skills together.\n' +
            '\n'+
            'Beyond that, I’ve taken online courses on ReactJS and Python Scrapy to improve my web development and data scraping skills. These are becoming increasingly important in QA.\n' +
            '\n'+
            'By learning from others and continuously developing my skills, I stay current with the latest QA practices and tools.\n' },
    { header: 'How to learn a new tool or technology', detail: 'Start with Company Resources\n' +
            'I begin by looking at available resources, such as documentation, user guides, or training materials provided by the company.\n' +
            'I follow these step-by-step and take notes, especially on parts I find difficult or unclear.\n' +
            'This helps me create my own quick reference guide for future use.\n' +
            '\nWatch Tutorials and Videos\n' +
            'I use online tutorials or video courses to see how experts use the tool.\n' +
            'Watching demos helps me understand the tool what and how it works.\n' +
            'Platforms like YouTube or Udemy often have helpful content.\n' +
            '\nAsk Team Members for Help\n' +
            'I talk to team members who have experience with the tool to ask questions or clarify my doubts.\n' +
            'Sometimes, I arrange knowledge transfer (KT) sessions to discuss specific topics or challenges.\n' +
            'Learning from their experience saves time and helps me avoid common mistakes.\n' +
            '\nHave Regular Check-Ins\n' +
            'I set up regular calls or check-ins with knowledgeable colleagues.\n' +
            'During these sessions, I discuss any issues I face, share my progress, and get immediate feedback.\n' +
            'This collaborative approach helps me learn faster and stay on the right track.\n' +
            '\nPractice and Experiment\n' +
            'I believe the best way to learn is by doing. I practice using the tool as much as possible.\n' +
            'play around with the tool or work on small task, or debug the code by adding breakpoint try to understand the logic\n' +
            'This hands-on experience helps me build confidence and makes the learning stick.\n' +
            '\nTest in Real Scenarios\n' +
            'Once I’ve learned the basics, I try using the tool on real projects or scenarios.\n' +
            'This helps me understand how it performs in real situations and highlights areas where I need more practice.\n' +
            '\nDocument What I Learn\n' +
            'I create my own notes, cheat sheets, or guides while learning.\n' +
            'Writing things down not only helps me remember but also allows me to share knowledge with others later.\n' +
            'This can be useful for onboarding new team members in the future.\n' +
            '\nStay Open to Feedback\n' +
            'I regularly ask for feedback from team members or my manager to ensure I’m using the tool correctly. and i aslo love to see my coworker review my word in github PR and provied feedback\n' +
            'Their suggestions help me improve and learn faster.'},

    { header: 'most useful tool in QA process', detail: '1. JIRA: Tracking Features and Bugs\n' +
            'JIRA is my go-to tool for tracking progress.\n' +
            'I create detailed tickets for each bug or feature, assign them to the right team members, and monitor their status throughout the development process.\n' +
            'It provides clear visibility into what needs to be done and helps the team prioritize work effectively.\n' +
            'Example: When we encountered a new feature with multiple bugs, I used JIRA to create tickets for each issue. This allowed the team to track fixes and understand who was responsible for each task.\n' +
            '\n' +
            '2. Jenkins: Automating Builds and Tests\n' +
            'Jenkins helps us with continuous integration and deployment (CI/CD).\n' +
            'I schedule daily builds and automated tests to catch bugs early in the development cycle.\n' +
            'This proactive approach reduces the risk of major problems appearing later.\n' +
            'Example: Using Jenkins to run automated tests daily helped us identify issues quickly during a recent release, improving the product’s stability.\n' +
            '\n' +
            '3. TestRail: Managing Test Cases\n' +
            'TestRail is a great tool for organizing and managing test cases.\n' +
            'I use it to create, update, and track test scenarios and their results.\n' +
            'It provides a clear overview of testing progress and ensures that no test cases are missed.\n' +
            'and i can also config the code to upload all the test result to the platform, and review the result in each sprint to find out the fakly test to enhance\n'+
            'Example: By using TestRail, I can easily collaborate with the team and keep all test cases accessible in one place.\n' +
            '\n' +
            '4. Postman: Testing APIs\n' +
            'Postman is essential for manual API testing.\n' +
            'It allows me to create, run, and organize API requests. I also use collections in Postman to group related tests and share them with team members.\n' +
            'This ensures consistent API testing practices across the team.\n' +
            'Example: During backend testing, I used Postman collections to verify API responses, making it easier to identify issues and share my work with the team.\n' +
            '\n' +
            '5. Selenium: Automating Web Application Tests\n' +
            'Selenium is my primary tool for automating repetitive web application tests.\n' +
            'It supports multiple programming languages and browsers, making it flexible for different projects.\n' +
            'By automating tests, I save time and ensure consistent results across different environments.\n' +
            'Example: I used Selenium to automate login functionality tests, reducing manual effort and speeding up regression testing.\n' +
            '\n' +
            '6. Excel: Writing and Managing Test Cases\n' +
            'Excel provides a simple and flexible way to organize test scenarios, expected results, and actual outcomes.\n' +
            'I use Excel to draft my test cases and later update this information in TestRail to maintain proper test management.\n' +
            'Example: I initially wrote detailed test cases for a feature in Excel before transferring them to TestRail, making it easy to share with the team.' },
    { header: 'QA process in an Agile environment', detail: 'Team Collaboration: I work with team from the beginning of the project to understand the requirements and set goals on product quality. Daily meetings to catch problems early.\n' +
            '\nStart Testing Early: I review requirements, create user stories, and acceptance criteria as early as possible and review it with the team, this will give an idea to the team on what and how i will do testing.\n' +
            '\nFocus on Risks: I prioritize testing based on how important the feature is. This saves time while focusing on critical areas.\n' +
            '\nThink Like a User: I test from the user’s point of view to make sure the product is easy and reliable to use.\n' +
            '\nAutomate in CI/CD: I automate important tests and add them to the CI/CD pipeline, and had it running on every PR that will help to catch bugs early.\n' +
            '\nImprove Every Sprint: After each sprint, attend the sprint retro meeting, review with the team on what need to be done better, and how to improve it in the future.' },
    { header: 'techniques do API testing', detail: 'Understand API Specs: I Understand API expected behaviors fouse on endpoints, http method, data formats, and data flow and how it will impact the application.\n' +
            '\nFunctional Testing: I test all scenarios, including valid and invalid inputs, to ensure the API performs as expected and handles errors properly.\n' +
            '\nAutomated Testing: I use tools like Postman and Python’s requests library to automate checks for status codes, response data, and data accuracy.\n' +
            '\nCI/CD Integration: I add API tests to the CI/CD pipeline to catch issues early during development.\n' +
            '\nThese steps help me deliver APIs that are reliable, secure, and high-performing.\n' },
    { header: 'important qualities for QA engineer', detail: '' +
            'Good Communication: Explaining bugs and sharing ideas with the team is very important. \n' +
            '\nUnderstand the Business: Before testing, I make sure I know what the feature is for and why it’s needed. This helps me design test cases, including happy paths, negative tests, and conor cases.\n' +
            '\nAttention to Detail: document every step of the testing process so everyone can follow alone. And including every detail in the bug ticket.\n' +
            '\nThink outside the box. Think about unusual situations and try to break the application. It helps in uncovering hidden defects.\n' },
    { header: 'perfer Automation tools', detail: 'Playwright for UI Testing: I primarily use Playwright with Python for UI testing. It allows me to automate browser interactions effectively, ensuring that the user interface behaves as expected across different browsers.\n' +
            '\nPython Requests for API Testing: For API testing, I utilize the requests library in Python. This tool enables me to send HTTP requests and validate responses, making it easy to test various API endpoints.\n' +
            '\nPostman for Manual API Testing: I also rely on Postman for manual API testing. It provides a user-friendly interface to test APIs, and I appreciate its ability to organize requests into collections, which helps streamline the testing process.\n' +
            '\nPostman Collections for Test Data Generation: I often use Postman collections to generate test data, which is particularly useful for ensuring that my tests cover a wide range of scenarios.\n' +
            '\nJenkins for CI/CD: I integrate my automated tests into Jenkins for continuous integration and continuous deployment (CI/CD). This setup allows for automated testing with every code change, ensuring that any issues are identified early in the development cycle.\n' +
            '\nCharles Proxy to modify the api response before display on the UI.\n' },
    { header: 'handle tight deadlines', detail: 'At Planet Howl, I often tested checkout processes for merchants before their campaigns started. During non-holiday season, this was manageable. but for major events like Black Friday and Cyber Monday, the workload became overwhelming as many merchants launched campaigns at the same time. And just thing about it the platform has over 100 merchant, it will be improssable to do all al them, i will have to look up the historical data and determal which platform and browser i ned to do, this will be alot of works.\n' +
            '\nCampaign Calendar: I worked with the Customer Success Management (CSM) team and suggest them to create the campaign calendar. This helped set priorities and expectations.\n' +
            '\nFor non-holiday season, the CSM team will share detail 2 week before campaign start\n' +
            '\nFor holiday season, The CSM team played a crucial role in reaching out to individual merchants to confirm the campaign detail at lease 1 month before campaign start.\n' +
            '\nI will also setup meeting with different Stakeholder to determine the top 20 hight traffic merchant and the platform and browser base on the historical transition data. \n' +
            '\nFor promation code relate test we can either request from the merchant for testing propose or use the tools like Honey Chrome extension to search for applicable promotion codes online. This saved us valuable time during testing.\n' +
            '\nRequest additional resource, and divided testing tasks among QA engineers, assigning specific merchants and platforms to each team member.\n' +
            '\nBy following this process, my team successfully completed testing, ensuring that tracking tag’s functionality for holiday season although we not able to test every merchant but we could ensure that our testing had make the most impact.\n' },

    { header: 'biggest challenge in QA today', detail: 'I think the biggest challenge in QA today is having too little time for testing. When projects have requirements change on  tight deadlines, testing can feel rushed. This might mean changing test plans without enough time to fully check everything.\n' +
            'To handle this, I focus on these key points:\n' +
            '\nPrioritization: I focus on testing the most important parts of the application first. This ensures that the critical functions are tested even when time is short.\n' +
            '\nClear Communication: I talk openly with developers and product teams about timelines and risks. This helps us plan better and adjust deadlines when possible.\n' +
            '\nAutomation: I use automation for repeated tests. This saves time and allows me to run more tests quickly, covering more areas even under tight schedules.\n' +
            '\nThese strategies help me manage short timelines while still delivering quality results.\n' },
    { header: 'project requirements change', detail: '1. Situation\n' +
            'During a project, we received a new requirements document that introduced changes to the features we were testing.\n' +
            'The changes were unexpected and required us to adapt quickly to avoid delays.\n' +
            '\n2. Task\n' +
            'My responsibility was to understand the new requirements, update our testing approach, and ensure that testing was aligned with the new scope.\n' +
            'It was also important to communicate with the team to manage expectations and address any risks.\n' +
            '\n3. Action\n' +
            'Step 1: Analyze the Changes\n' +
            'I carefully reviewed the new document to identify all changes and their impact on the features being tested.\n' +
            'I made a list of questions or areas needing clarification.\n' +
            '\nStep 2: Collaborate with the Team\n' +
            'I organized a meeting with the developers, product owners, and other QA members to confirm the changes and clarify my questions.\n' +
            'During the meeting, we discussed potential challenges and whether the delivery timeline needed to be adjusted.\n' +
            '\nStep 3: Update Test Cases\n' +
            'I reviewed and updated the test cases based on the new requirements.\n' +
            'I prioritized critical test cases that aligned with the most important features to ensure we met the new goals.\n' +
            '\nStep 4: Communicate Regularly\n' +
            'I actively participated in daily stand-up meetings to share updates on testing progress and any blockers caused by the requirement changes.\n' +
            'This helped keep everyone informed and ensured we resolved issues quickly.\n' +
            '\n4. Result\n' +
            'By following this approach, we successfully adapted our testing strategy to the new requirements.\n' +
            'The final product met the updated expectations, and we delivered it without significant delays.\n' +
            'The collaboration and clear communication helped minimize disruptions and kept the team aligned.\n' +
            '\nKey Takeaway\n' +
            'This experience taught me the importance of flexibility and clear communication when dealing with unexpected changes. By staying organized and working closely with the team, we were able to handle the situation effectively.' },


    { header: ' feedback and criticism in your QA role', detail: 'I believe that every piece of feedback or criticism makes me stronger and helps me grow as a QA professional. Here’s how I handle it:\n' +
            '\nOpen Mindset: I approach feedback with an open mind. I understand that it’s an opportunity to learn and improve my skills.\n' +
            '\nReview and Reflect: When I receive feedback, I take the time to review what I did and identify what went wrong. I analyze the situation to understand how I can do better next time during the sprint retro call.\n' +
            '\nImplement Changes: I make a plan to avoid repeating the same mistakes in the future. This could involve adjusting my testing processes, improving communication with my team, or enhancing my technical skills.\n' +
            '\nSeek Clarification: If the feedback is not clear, I don’t hesitate to ask for more details. This helps me understand the perspective of others and ensures that I fully grasp the areas for improvement.\n' +
            '\nBy embracing feedback and using it as a tool for growth, I can continuously enhance my performance and contribute more effectively to my team.\n' },

    { header: 'ensure effective communication', detail: 'Effective communication within the QA team and with other departments is critical to the success of any project. Here are the key strategies I follow:\n' +
            '\bRegular Meetings\n' +
            'I organize regular meetings like daily stand-ups and weekly reviews to keep the QA team aligned.\n' +
            'These meetings provide a platform for team members to share updates, discuss challenges, and ensure everyone is focused on the project goals.\n' +
            '\n2. Clear Documentation\n' +
            'I prioritize creating and maintaining clear, concise documentation, including test plans, test cases, and defect reports.\n' +
            'This ensures that everyone—whether in QA, development, or product management—can easily understand and follow the testing process and results.\n' +
            '\n3. Collaboration Tools\n' +
            'I use tools like Slack and JIRA to facilitate real-time communication.\n' +
            'These platforms allow the team to ask questions, share progress, and resolve issues efficiently.\n' +
            'I encourage using dedicated channels for specific projects to keep discussions organized.\n' +
            '\n4. Cross-Department Meetings\n' +
            'I arrange meetings with developers, product managers, and other stakeholders during the planning and review phases.\n' +
            'These sessions help clarify requirements, align expectations, and gather feedback.\n' +
            'I ensure the QA perspective is represented by highlighting risks and testing needs.\n' +
            '\n5. Feedback Loops\n' +
            'I encourage open feedback between QA and other teams.\n' +
            'After each release, I facilitate retrospectives to discuss what worked well and what could improve.\n' +
            'This helps foster trust and continuous improvement.\n' +
            '\n6. Training and Knowledge Sharing\n' +
            'I promote knowledge-sharing sessions within QA and across teams.\n' +
            'For example, I host workshops on new tools or methodologies, which improve skills and encourage collaboration.\n' +
            '\n7. Active Listening\n' +
            'During discussions, I practice active listening by focusing on what others say, asking clarifying questions, and acknowledging their input.\n' +
            'This approach builds trust and ensures everyone feels heard and valued.\n' +
            '\n8. Clear Roles and Responsibilities\n' +
            'I ensure that all team members understand their roles and responsibilities in the project.\n' +
            'This clarity helps reduce misunderstandings and overlaps, leading to smoother collaboration.\n' +


            '\n\nPractical Example of Effective Communication in Action\n' +
            '\nSituation: At Nationwide, our QA team had to validate files in various formats, including CSV, JSON, YAML, XML, flat files, and PDFs. Flat files were especially time-consuming because testers had to manually extract data from specific indexes.\n' +
            '\nTask: As an automation developer, my role was to validate files generated by different subsystems. This required collaboration with teams from billing, claims, rating, and underwriting—each with unique file logic and requirements.\n' +
            '\nAction:\n' +
            'I worked closely with business owners to gather detailed information about their file requirements.\n' +
            'I collaborated with the team to design a new testing framework for automating the validation process.\n' +
            'This framework used configurable settings and CSV files to control inputs, automatically fetched data from databases or APIs, generated expected files, and compared them with actual files to create a detailed report.\n' +
            '\nResult:\n' +
            'The new tool reduced testing time by over 90% and significantly minimized human error.\n' +
            'This automation made our testing process much more efficient and reliable, saving time and improving accuracy.\n' +
            '\n\nKey Takeaway\n' +
            'By combining effective communication strategies with strong collaboration, clear documentation, and automation, I’ve successfully improved team efficiency and project outcomes.'},



    { header: 'approach test case design', detail: 'Review the Product Requirement Document (PRD): I start by carefully reviewing the PRD to understand the requirements and the rationale behind them. This step is crucial as it helps me grasp the overall goals of the project and the specific functionalities that need to be tested. Understanding the "why" behind each requirement allows me to align my testing efforts with the business objectives.\n' +
            '\nBreak Down Requirements: During planning meetings with the team, I collaborate to break down the requirements into smaller, manageable features. This collaborative approach ensures that all team members have a shared understanding of the features and their implications for testing. It also allows us to identify dependencies and potential challenges early in the process.\n' +
            '\nDevelop Comprehensive Test Cases: For each feature, I develop detailed test cases that cover all possible scenarios. This includes:\n' +
            ' ---> Happy Path: Testing the expected behavior when the application is used as intended.\n' +
            ' ---> Corner Cases: Exploring edge cases that might not be immediately obvious but could lead to unexpected behavior.\n' +
            ' --->  Invalid Inputs: Testing how the application handles erroneous inputs, which is critical for ensuring robust error handling and user experience.\n' +
            '\nReview Test Cases with the Team: After drafting the test cases, I conduct a review session with the team. We go through each test case together to ensure that all scenarios are covered and that the test cases are clear and actionable. This collaborative review helps identify any gaps in coverage and fosters a sense of ownership among team members.\n' +
            '\nIncorporate Feedback and Iterate: I actively seek feedback from team members during the review process and make necessary adjustments to the test cases. This iterative approach ensures that the test cases are refined and aligned with the team’s understanding of the requirements.\n' +
            '\nPrioritize Test Cases: I prioritize test cases based on risk and impact. This means focusing on critical functionalities first, ensuring that the most important features are tested thoroughly before moving on to less critical areas.\n' +
            '\nContinuous Improvement: After each testing cycle, I review the effectiveness of the test cases and gather insights from the outcomes. I analyze any defects found and adjust the test cases accordingly for future iterations. This continuous improvement mindset helps enhance the quality of the test cases over time.\n' +
            '\nBy following this structured approach to test case design, I can ensure comprehensive coverage, improve collaboration with my team, and ultimately contribute to delivering high-quality software products.\n' },

    {header: 'differences between manual testing and automated testing', detail: '**Manual testing** involves a human tester interacting with a software application to identify defects. It\'s like a real user going through the application and checking if it behaves as expected. It\'s flexible, allowing for exploratory testing and ad-hoc checks. However, it\'s time-consuming, prone to human error, and doesn\'t scale well for repetitive test cases.\n' +
            '\n' +
            '**Automated testing**, on the other hand, uses software tools and scripts to execute test cases. This method is faster, more reliable, and can handle repetitive tasks efficiently. It\'s ideal for regression testing and large test suites. However, it requires initial setup time, technical expertise, and might not be suitable for all test scenarios, especially those requiring human judgment or intuition.\n' +
            '\n' +
            'In essence, manual testing is about human interaction and exploration, while automated testing is about efficiency, repeatability, and coverage for specific test cases. Both have their strengths and weaknesses, and often, they complement each other in a well-rounded testing strategy. \n'},
    { header: 'Common QA challenge', detail: 'Unclear Requirements, Problem: It’s hard to test when the project details are not clear.\n' +
            'Solution: Talk with the team to make sure everyone understands the requirements. Write everything down to avoid confusion.' +

            '\n\nPoor Communication: Team members don’t share information clearly, causing delays or mistakes.\n' +
            'Solution: Use chat tools like Slack or Jira and have regular team meetings to stay updated.'+

            '\n\nTight Deadlines: and there’s not enough time to test everything.\n' +
            'Test the most important parts first. Use tools to automate repeated tests to save time' +

            '\n\nNo Test Data: don’t have enough or the right data to test.\n'+
            'Create fake data or copy safe data from the real system to use for testing'+

            '\n\nThe testing system doesn’t work properly\n'+
            'Use tools like Docker to create stable systems. Work with the DevOps team to fix problems quickly\n'+

            '\nHard to Manage Test Automation: It’s tricky to pick the right tools or keep automated tests working.\n' +
            'Solution: Start small, automate important tests, and use good tools with trained testers.\n' +

            '\nBugs in Production: Some bugs still show up after release.\n' +
            'Solution: Focus on testing critical parts, test often, and do a final test before release.\n' +
            '\nManual vs. Automated Testing: Choosing when to use manual testing or automation is difficult.\n' +
            'Solution: Use manual testing for creative work and automation for repeated tasks.\n' +
            '\nNot Enough Resources: There aren’t enough testers, tools, or money.\n' +
            'Solution: Use free tools and train team members to share the work.\n' +
            '\nTest Coverage vs. Time: Testing everything takes too much time.\n' +
            'Solution: Focus on testing the most important and risky parts first.\n'
    },

    { header: 'Common Issue in Manual Testing', detail: 'Human Error: Problem: Testers can make mistakes or forget steps.\n' +
          'Example: Missing a test step or writing the wrong result.\n' +
          'Solution: Write clear steps to follow (test cases).\n' +
          'Double-check your work or ask someone else to review it.\n' +

          '\nsome bug are not able to reproduce: Testers find a bug but can’t recreate it later.\n' +
          'Example: A crash happens once but doesn’t happen again.\n' +
          'Solution: Write down the exact steps to create the bug, Test on different devices or browsers to see if the issue repeats.\n' +


          '\nProblem: The system for testing doesn’t work properly for Example: The server is down or deployment time\n' +
          'Solution: work with the platform team, asn them to provide detail timeline in the future' +

          '\nTime-Consuming Processes: Manual testing can be very time-consuming, especially for large applications with many features. Testers spend significant time executing test cases and documenting results.\n' +
          'Impact: This can lead to tight deadlines, making it challenging to perform thorough testing.\n' +
          '\nLack of Reusability: Each time a new version of the application is released, testers may need to start from scratch or modify existing cases extensively.\n' +
          'Impact: This results in wasted effort and can slow down the testing process.'},

    { header: 'how to do manual testing', detail: '1. Understand the Requirements: Read the project documents or user stories to understand how the app should work.\n' +
          'Ask questions if something is unclear.\n' +
          'Example: If testing a login page, understand what happens when the username or password is wrong.\n' +

          '\nPrepare Test Cases: Write clear test cases with steps, expected results, and inputs.\n' +
          'Cover all scenarios: normal cases, edge cases, and negative cases.\n' +
          'Example:\n' +
          'Test Case: Enter valid username and password → Expected Result: User logs in.\n' +
          'Test Case: Leave the username empty → Expected Result: Error message shows.\n' +

          '\nSet Up the Test Environment,\n' +
          'Make sure the system or app is ready for testing. and use the latest code provied by developer\n' +
          'Check if the test environment matches the real user environment (e.g., browser, device).\n' +
          'Example: Test a mobile app on Android and iOS devices.\n' +

          '\nExecute Test Cases: Follow the steps in your test cases one by one.\n' +
          'Compare the actual results with the expected results.\n' +
          'Example: Enter the username and password, click "Login," and check if it works as expected.\n' +

          '\nRecord Results: Write down whether each test passed or failed.\n' +
          'Include details like screenshots or steps if the test failed.\n' +
          'Example: Write “Login test failed because the system crashed” and attach a screenshot.\n' +

          '\nReport Bugs: Report any issues you find in a bug tracking tool like Jira or testrail.\n' +
          'Include details: Steps to reproduce the bug., Screenshots or videos.\n' +
          'Example:\n' +
          'Bug Description: "The login button doesn’t work."\n' +
          'Steps: "Click the login button after entering valid credentials."\n' +

          '\nRetest Fixed Bugs: After developers fix the bugs, test them again to ensure the issue is resolved.\n' +
          'Check that the fix doesn’t cause new bugs.\n' +
          'Example: If the login button bug is fixed, retest it and check other buttons on the page too.\n' +


          '\nCreate a Test Report: Summarize the testing process and results.\n' +
          'Include: Total tests run, Number of passed and failed tests, and List of bugs.\n' +
          'Example: “We tested 20 cases, 15 passed, 5 failed. 3 critical bugs were found.”\n' +

          '\nFollow Best Practices\n' +
          'Stay organized and write detailed test cases.\n' +
          'Always communicate clearly with your team.\n' +
          'Test like a real user: think of different ways people might use the app.\n' },

    {header: 'benefits of automation testing', detail: '* **Increased speed:** Automated tests execute much faster than manual tests, leading to quicker feedback cycles and faster time-to-market.\n' +
            '* **Improved accuracy:** Automation eliminates human error, resulting in more reliable test results.\n' +
            '* **Enhanced test coverage:** Automated tests can cover a broader range of test cases, including complex and repetitive scenarios.\n' +
            '* **Cost-effectiveness:** While there\'s an initial investment in setting up automation, it saves time and resources in the long run.\n' +
            '* **Improved test repeatability:** Automated tests can be executed consistently, ensuring that the same test conditions are applied each time.\n' +
            '* **Better resource allocation:** Automation frees up human testers to focus on exploratory and complex testing scenarios.\n' +
            '* **Early bug detection:** Automated tests can identify defects early in the development process, reducing costs and improving overall quality.\n'},

    { header: 'Common Issue in Automation Testing', detail: 'Test Script Maintenance: Automated test scripts break when the application changes.\n' +
          'Example: A button’s ID changes, and the test can’t find it.\n' +
          'Solution: Use dynamic locators like XPath or CSS selectors.\n' +
          'Update test scripts regularly as part of development cycle.\n' +

          '\nFlaky Tests: Tests fail sometimes and pass other times without any changes.\n' +
          'Example: A test fails due to timing issues, like a page loading slowly.\n' +
          'Solution: add retry config, Add waits (e.g., explicit waits) to ensure elements are ready.\n' +
          'Use stable environments for testing.\n' +


          '\nTool Limitations: The automation tool may not support some features.\n' +
          'Example: A tool can’t test mobile apps or advanced UI components.\n' +
          'Solution: Research and choose the right tool for your project (e.g., Appium for mobile, Selenium for web).\n' +
          'Use plugins or integrate multiple tools if necessary.\n' +

          '\nmaintain/setup Test Data: need to maintain or create Tests data\n' +
          'Solution: Use scripts to generate test data dynamically.\n' +
          'Save reusable data in a shared location for easy access.\n' +

          '\nDifficulty in Testing Dynamic Elements: Some UI elements, animations, are hard to test.\n' +
          'Solution: Use advanced locators or strategies like waiting for the element to become visible.\n' +
          'Work with developers to make UI elements more testable.\n' +

          '\nIntegration with CI/CD: Automated tests don’t run smoothly with continuous integration tools.\n' +
          'Solution: Integrate automation with CI/CD tools like Jenkins, GitHub Actions, or Azure DevOps.\n' +
          'Fix any environment issues before running the tests.\n' +

          '\nLimited Scope of Automation: Not all tests can be automated, especially those requiring human judgment or exploratory testing. Automation works best for repetitive tasks and stable functions.\n' +
          'Impact: This means that manual testing is still necessary.\n'+

          '\nAutomation script will not be available in code deployment time or system downtime'+
          'this will impact for both automation and manual test'+

          '\nBrowser/Platform Compatibility Issues: Automated tests fail on some browsers or devices.\n' +
          'Solution: Use cross-browser testing tools like BrowserStack or Sauce Labs.\n' +
          'Run tests in parallel on multiple platforms.' },


    { header: 'how to do automation test', detail: 'Understand What to Automate: Identify tests that take a lot of time if done manually.\n' +
          'Focus on repetitive tests, regression tests, and tests for critical functions.\n' +
          'Example: Automate login functionality and repetitive form submissions.\n' +


          '\nSet Up the Environment: set up config using docker to pull the image or code and build the application\n' +
          '\nset up testing framework using whatever best fit for the needs\n' +

          '\nDesign Test Scripts: Write scripts for your test cases using the automation tool.\n' +
          'follow coding stander (single use pricial)'+


          '\nRun Test Scripts: Execute the scripts and monitor the results.\n' +
          'Run tests in different environments (browsers, devices) to ensure compatibility.\n' +
          'Example: Run the login test on Chrome, Firefox, and Edge.\n' +

          '\nAnalyze Results: Check if all tests passed.\n' +
          'If a test fails, look at the error logs to find the issue.\n' +
          'Example: If a login test fails, the log might show "Element not found," meaning the locator is wrong.\n' +

          '\nMaintain and Update Scripts: Update scripts when the application changes (e.g., UI updates).\n' +
          'Regularly check and fix broken tests to avoid failures.\n' +
          'Example: If a button ID changes from "loginButton" to "submitButton," update the script.\n' +


          '\nIntegrate with CI/CD Tools: Set up automated tests to run after every code change.\n' +
          'Use tools like Jenkins, GitHub Actions, or Azure DevOps.\n' +
          'Example: Run automated tests automatically when developers push code to GitHub.\n' +

          '\nGenerate Reports: Create detailed test reports showing which tests passed or failed.\n' +
          'Use built-in reporting tools or plugins.\n' +
          'Example: Tools like TestNG or ExtentReports can generate HTML reports for better tracking.\n' +

          'Optimize and Expand Automation: Add more test cases to your automation suite.\n' +
          'Optimize scripts to run faster and cover more scenarios.\n' +
          'Example: Add tests for new features like "Forgot Password" or "User Registration."\n' +

          '\nBest Practices for Automation Testing\n' +
          'Start with simple tests before automating complex ones.\n' +
          'Write clean and reusable scripts for future use.\n' +
          'Use version control tools (like Git) to manage your scripts.\n' +
          'Combine manual and automation testing to achieve the best results.' },



    { header: 'what test to automate', detail: 'Automate repeat Tasks\n' +
          'Why? These tasks take a lot of time if done manually, and the steps are the same every time.\n' +
          'Examples: Login tests, Filling out forms repeatedly, Regression tests after every code change.\n' +

          '\nAutomate High-Risk Areas\n' +
          'or Prioritize Based on ROI (Return on Investment) Automating key functionalities used by most users.'+
          'Why? These areas are critical to the application and can cause major problems if they fail.\n' +
          'Examples: User account creation and authentication, Key business logic, like calculations the total cost\n' +


          '\nAutomate Tests That Run Often\n' +
          'Why? Tests that need to be repeated after every update or in every environment save the most time when automated.\n' +
          'Examples:\n' +
          'Smoke tests to check if the basic functions work.\n' +
          'Regression tests to ensure new changes don’t break existing features.\n' +

          '\nAutomate Tests with Large Data Sets\n' +
          'Why? It’s difficult and time-consuming to manually test with many inputs or large datasets.\n' +
          'Examples:\n' +
          'Testing a search feature with hundreds of search terms.\n' +
          'Validating file uploads or bulk data processing.\n' +

          '\nAutomate Stable Features\n' +
          'Why? Features that don’t change often are ideal for automation because the scripts won’t need frequent updates.\n' +
          'Examples:\n' +
          'APIs with a fixed contract.\n' +
          'Backend services that perform consistent operations.\n' +

          '\nAvoid Automating These for Now\n' +
          'Why? Some tests are better done manually because automation isn’t practical or cost-effective.\n' +
          'Examples:\n' +
          'Exploratory Testing: Testing new features where creativity is needed.\n' +
          'Usability Testing: Checking the look and feel of the application.\n' +
          'Unstable Features: New or frequently changing features that will require constant updates to scripts.\n'},



    { header: 'how to debug the bug', detail: 'Step 1: Understand the Bug\n' +
            '--> Reproduce the bug by following the same steps as the user or tester.\n' +
            '--> Read any error messages or logs to understand what went wrong.\n' +
            '--> Note the inputs, actions, and environment where the bug occurred (e.g., browser, OS).\n' +
            'Tip: Use screenshots or videos to document the issue.\n' +
            '\nStep 2: Investigate the Cause\n' +
            '--> Check the code or workflow for the part of the application where the bug occurs.\n' +
            '--> Use debugging tools to step through the code and monitor its behavior.\n' +
            '--> Analyze related logs (application, server, or database logs) for errors or warnings.\n' +
            '--> Review recent changes to the code or configuration that might have introduced the bug.\n' +
            'Tools:\n' +
            '--> Browser Developer Tools: For web debugging (Inspect element, Console).\n' +
            '--> IDE Debuggers: Debug features in tools like Visual Studio, IntelliJ, or PyCharm.\n' +
            '\nStep 3: Fix the Bug\n' +
            '--> Identify the root cause and update the code or configuration to fix the issue.\n' +
            '--> Use small, clear changes to avoid introducing new bugs.\n' +
            'Example: If the bug is caused by incorrect logic, rewrite the logic with the correct conditions.\n' +
            '\nStep 4: Test the Fix\n' +
            '--> Reproduce the original steps to ensure the bug is gone.\n' +
            '--> Run regression tests to make sure the fix doesn’t break other parts of the system.\n' +
            'Tip: Test in different environments (e.g., different browsers, devices) if the bug might be environment-specific.\n' +
            '\n\nStep 5: Analyze and Learn\n' +
            '--> Look for ways to prevent similar bugs in the future, like adding validation or more tests.\n' +
            '--> Share your findings with the team to improve the codebase or processes.\n' +
            'Example: Add unit tests to catch similar issues early.\n' +
            '\n\nBest Practices for Debugging\n' +
            'Stay Calm and Focused: Debugging can be frustrating, but working step by step helps solve issues faster.\n' +
            'Isolate the Issue: Break down the problem and check one thing at a time.\n' +
            'Use Logs: Logging is your best friend! Add helpful logs to trace what’s happening in the app.\n' +
            'Ask for Help if Needed: If you’re stuck, ask a teammate or check online forums like Stack Overflow.' },

    { header: 'Nationwide File validation', detail: '\n\nPractical Example of Effective Communication in Action\n' +
            '\nSituation: At Nationwide, our QA team had to validate files in various formats, including CSV, JSON, YAML, XML, flat files, and PDFs. Flat files were especially time-consuming because testers had to manually extract data from specific indexes.\n' +
            '\nTask: As an automation developer, my role was to validate files generated by different subsystems. This required collaboration with teams from billing, claims, rating, and underwriting—each with unique file logic and requirements.\n' +
            '\nAction:\n' +
            'I worked closely with business owners to gather detailed information about their file requirements.\n' +
            'I collaborated with the team to design a new testing framework for automating the validation process.\n' +
            'This framework used configurable settings and CSV files to control inputs, automatically fetched data from databases or APIs, generated expected files, and compared them with actual files to create a detailed report.\n' +
            '\nResult:\n' +
            'The new tool reduced testing time by over 90% and significantly minimized human error.\n' +
            'This automation made our testing process much more efficient and reliable, saving time and improving accuracy.\n' +
            '\n\nKey Takeaway\n' +
            'By combining effective communication strategies with strong collaboration, clear documentation, and automation, I’ve successfully improved team efficiency and project outcomes.'},

    { header: 'Pixel Script', detail: '1. Situation\n' +
            'When I joined Planet Howl, the QA team was manually testing checkout processes for active merchants based on revenue. This process, conducted monthly and quarterly, was repetitive and time-consuming.\n' +
            'Additionally, I observed that 5%-10% of product support tickets were related to configuration issues caused by changes on merchant sites.\n' +

            '\n2. Task\n' +
            'My goal was to find a way to automate the testing process to:\n' +
            'Reduce manual workload.\n' +
            'Quickly identify configuration issues without requiring actual checkouts or handling real credit cards.\n' +
            'Proactively address issues to improve customer satisfaction.\n' +
            '\n3. Action\n' +
            'I proposed an automated solution and drafted a Notion document explaining my approach. After discussing it with my manager, I requested a week to develop the solution.\n' +
            'Using Selenium, I created a script with the following steps:\n' +
            'Access each product URL and wait for a few seconds to load the page.\n' +
            'Capture and read the network requests to verify if the page impression was present in the network.\n' +
            'Dump all impression details into a CSV file.\n' +
            'Use the CSV data to generate database queries based on timestamp, merchant ID, creator ID, and product ID.\n' +
            'Validate the data in the database and set the status column to either "Pass" or "Fail" to indicate whether the merchant’s tag was functioning correctly.\n' +
            'For failed cases, I created JIRA bug tickets and shared them with the CSM team.\n' +
            '\n4. Result\n' +
            'The automated script efficiently identified merchants with tag issues, significantly reducing the need for manual testing.\n' +
            'The proactive approach allowed the CSM team to address issues before customers noticed them, improving customer satisfaction.\n' +
            'This solution saved time, reduced human error, and streamlined the QA and CSM workflows.' },
    { header: 'Team Change', detail: 'Managing a Smooth Team Change During a Reorganization\n' +
            '\n1. Situation\n' +
            'Due to a company reorganization, I was transitioned from the publisher support team to the merchant team. The publisher support team focused on activities like managing publisher tags, reports, and monitoring tag health. At the time, the team was working on a new feature to track link interactions on publisher websites, including user scrolls, views, and hovers over links.\n' +
            '\n2. Task\n' +
            'As the only QA on the project, my task was to ensure a smooth transition of the project to a new QA team member. This involved transferring all knowledge and responsibilities so the project could continue seamlessly and meet its deadlines.\n' +
            'Documentation:\n' +
            'I created detailed documents covering all aspects of the project, including test cases, test results, and ongoing tasks.\n' +
            'These documents served as a complete reference for the new team member.\n' +
            'Knowledge Transfer (KT) Sessions:\n' +
            'I hosted daily KT meetings to walk the new team member through the project, addressing their questions and concerns in real time.\n' +
            '\nCollaboration and Support:\n' +
            'I participated in stand-up meetings every other day with the broader team to identify and resolve potential issues during the transition.\n' +
            'This ensured alignment between QA and development teams.\n' +
            '\nAvailability for Follow-Up:\n' +
            'I made myself available for any follow-up questions or guidance, ensuring the new QA team member felt supported throughout the transition process.\n' +
            '\n4. Result\n' +
            'The new team member successfully took over the project without interruptions or delays.\n' +
            'The feature was delivered on time, and integration tests were completed across all active publishers.\n' +
            'The transition process was smooth, and the new feature was implemented effectively.\n' +
            '\n\nKey Takeaway\n' +
            'This experience taught me the importance of clear documentation, effective knowledge transfer, and ongoing support during team transitions. These practices ensured continuity and contributed to the project’s success.' },
    { header: 'Pixel Debug', detail: 'I remember a tricky issue during an Ulta Beauty campaign that required careful investigation. On the first day, I noticed the order transition data was lower than expected, which seemed strange.\n' +
            '\nConfirmed the campaign date on the calendar\n' +
            '\nLoad the product link to confirm the tracking tag is able to load up on the product page\n' +
            '\nVerify the order transition on the event table to confirm the tracking tag is working\n' +
            '\nAfter above step i notice the tacking tag is working as expected, then i suspect some product might not trigger the checkout api call\n' +
            '\nThen I reach out to the CSM team to get all the campaign products and double check them on the event table by grouping the product by name with the transition count in the past date, and i still don\'t have any idea, the result looks fine\n' +
            '\nAnd after some back and forth data checking i suspect it might relate to the platform, then i modify the SQL to group by platform and browser, and i notice on IOS with Safari browser data was a lot lower than expected\n' +
            '\nAnd i start to do the manual checkout on ios and safari, and i see there is not checkout api call after at all\n' +
            '\nRoot Cause: After identifying the problem, I scheduled a meeting with both our team and the Ulta team. I also created a JIRA ticket with all the details, including steps to reproduce, product links, platforms, browsers, order details, and browser network call.\n' +
            '\nResolution: During the meeting, the Ulta team confirmed a configuration issue on their end for iOS Safari because they had some other bug related to IOS and Safari. And they fixed it, I retested on all platforms and browsers to confirm the tracking tag was working.\n' +
            '\n\nDocumenting for the Future:\n' +
            'I created a guide to help in case a similar bug happens again. It includes:\n' +
            'Steps to confirm campaign details\n' +
            'End-to-end testing procedures\n' +
            'SQL queries for grouping data by platform and browser\n' +
            'How to gather data for JIRA tickets\n' +
            'Tips for collaborating with external teams\n' +
            '\nBy following these steps and working closely with the team, we fixed the issue efficiently.\n' },
    { header: 'STLC', detail: 'Requirement Analysis\n' +
            'Test Planning\n' +
            'Test Case Development\n' +
            'Test Environment Setup\n' +
            'Test Execution\n' +
            'Test Cycle Closure\n' },
    { header: 'SDLC', detail: 'Planning\n' +
            'Analysis\n' +
            'Design\n' +
            'Implementation (Coding)\n' +
            'Testing\n' +
            'Deployment\n' +
            'Maintenance and Support\n' },
    { header: 'Smoke vs Regression', detail: 'Smoke tests to check if the basic functions work.\n' +
            'Regression tests to ensure new changes don’t break existing features.\n'},
    { header: 'http method and status code', detail: 'Informational responses (100 – 199) \n' +
            'Successful responses (200 – 299) \n' +
            'Redirection messages (300 – 399) \n' +
            'Client error responses (400 – 499) \n' +
            'Server error responses (500 – 599)\n'+

            '\nGet: get/retrive information from resource - get user information\n' +
            'Post: insert information into resource - create new user (name, address, age, etc)\n' +
            'Put: update data from existing by providing new data (udpate user with new data)\n' +
            'Patch: only update specific field (udpate user name)\n'},
    { header: 'wait', detail: '### 1. **Explicit Waits:**\n' +
            '* Employing `WebDriverWait` or similar mechanisms to wait for specific conditions before interacting with the element.\n' +
            '* Useful for elements that appear after certain actions or delays.\n' +
            '* Example: Waiting for an element to be clickable or visible before clicking it.\n' +
            '\n' +
            '### 2. **Implicit Waits:**\n' +
            '* Setting a global timeout for all find element operations.\n' +
            '* Less preferred than explicit waits as it can lead to unnecessary delays.\n' +
            '\n' +
            '### 3. **Fluent Waits:**\n' +
            '* Combining explicit and implicit waits for more flexible control.\n' },
    { header: 'Contract Testing', detail: 'Contract testing is a type of testing that ensures the communication between two services (like microservices) works as expected. It checks that both parties (the provider and the consumer) agree on how they will interact. In simpler terms, it verifies that the service providing data sends what the service requesting data expects to receive.\n' +
            'Key Features of Contract Testing:\n' +
            'Consumer-Driven: Contract testing is often driven by the consumer\'s needs. The consumer defines what they expect from the provider.\n' +
            'Contracts: A "contract" is like an agreement. It describes the expected input (request) and output (response) between services. If both sides follow this contract, they should work well together.\n' +
            'Isolation: Contract testing can be done in isolation, meaning you can test the consumer and provider independently. This is useful when one service is not yet fully developed.\n' +
            'Fast Feedback: It provides quick feedback when changes are made, helping to catch issues early before they reach production.' },
    { header: 'Integration Testing', detail: 'Integration testing is the process of testing how different components or services work together as a whole. It checks whether the integrated parts of an application interact correctly and identify any issues that arise when they are combined.\n' +
            'Key Features of Integration Testing:\n' +
            'Whole System Testing: Integration testing focuses on the interactions between various components, features, or systems. It tests the complete flow of data and behavior.\n' +
            'Environment Setup: This type of testing usually requires a specific environment where all components are set up and can interact with each other.\n' +
            'Detects Interface Issues: Integration testing is useful for finding problems that occur at the interfaces between components, such as data mismatches or communication failures.\n' +
            'End-to-End Scenarios: It often involves running end-to-end scenarios to ensure the entire system works as intended.' },
    { header: 'Contract vs integration testing', detail: 'Focus\n' +
            'Contract Testing: Verifies the interactions between a consumer and provider based on a contract.\n' +
            'Integration TestingTests how different components or services work together as a whole.\n' +
            '\n' +
            'Level of Testing\n' +
            'Contract Testing: More granular, focusing on specific interactions.\n' +
            'Broader, focusing on complete workflows.\n' +
            '\n' +
            'Isolation\n' +
            'Contract Testing: Can be done independently without needing the other service to be fully functional.\t\n' +
            'Integration TestingIntegration TestingRequires all components to be set up and integrated.\n' +
            '\n' +
            'Purpose\t\n' +
            'Contract Testing: Ensures both parties agree on the data exchange and Integration Testingcommunication.\tDetects issues in the integration of various parts of the application.\n' +
            '\n' +
            'Development Stage\n' +
            'Contract Testing: Often used during development to catch issues early.\n' +
            'Integration TestingUsed after components are developed to ensure they work together properly.' },
    { header: 'Header', detail: 'Detail' },

    { header: '算法面试注意事项', detail: '上来不要直接去做题!!!一定要问清楚题目要求!!!\n' +
            'Ask question to clearify any unsure question\n' +
            'Try all provide testcase\n' +
            'Comup with more testcase corner case\n' +
            '不论遇到做过/没做过的题不要看完之后直接说答案。可以安静思考2-5分钟，思路总结好了讲给面试官听可以一边写bullet point一边讲 - walk thougth the steps with testcase\n' +
            '得到面试官确认之后再开始写代码\n' +
            '写完程序之后一定要看下代码\n' +
            '写完程序之后一定要再次考虑是否有corner cases\n' +
            '主动跑/手动跑test case，至少要把面试官提供的examples跑一下\n' +
            '面试官可能会问test case还有哪些情况、时间复杂度、空间复杂度\n' +
            '遇到想不出来的题果断要hint!\n' +
            '多Mockup才能保持好心态!\n' },
];
